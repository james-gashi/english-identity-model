{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd8ae26",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [1]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526c3db3",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a33ccc5-764c-43ca-9e96-45e919964505",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T03:51:06.630233Z",
     "iopub.status.busy": "2025-04-25T03:51:06.629924Z",
     "iopub.status.idle": "2025-04-25T03:51:23.102341Z",
     "shell.execute_reply": "2025-04-25T03:51:23.101773Z"
    },
    "papermill": {
     "duration": 16.528046,
     "end_time": "2025-04-25T03:51:23.102995",
     "exception": true,
     "start_time": "2025-04-25T03:51:06.574949",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\r\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/0e/6b/87fcddd34df9f53880fa1f0c23af7b6b96c935856473faf3914323588c40/torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\r\n",
      "Requirement already satisfied: filelock in /curc/sw/anaconda3/2023.09/lib/python3.11/site-packages (from torch) (3.9.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/jala6738/.local/lib/python3.11/site-packages (from torch) (4.13.2)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/jala6738/.local/lib/python3.11/site-packages (from torch) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /curc/sw/anaconda3/2023.09/lib/python3.11/site-packages (from torch) (3.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jinja2 in /curc/sw/anaconda3/2023.09/lib/python3.11/site-packages (from torch) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /curc/sw/anaconda3/2023.09/lib/python3.11/site-packages (from torch) (2023.4.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/jala6738/.local/lib/python3.11/site-packages (from torch) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/jala6738/.local/lib/python3.11/site-packages (from torch) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/jala6738/.local/lib/python3.11/site-packages (from torch) (12.6.80)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\r\n",
      "  Obtaining dependency information for nvidia-cudnn-cu12==9.5.1.17 from https://files.pythonhosted.org/packages/2a/78/4535c9c7f859a64781e43c969a3a7e84c54634e319a996d43ef32ce46f83/nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata\r\n",
      "  Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/jala6738/.local/lib/python3.11/site-packages (from torch) (12.6.4.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\r\n",
      "  Obtaining dependency information for nvidia-cufft-cu12==11.3.0.4 from https://files.pythonhosted.org/packages/8f/16/73727675941ab8e6ffd86ca3a4b7b47065edcca7a997920b831f8147c99d/nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/jala6738/.local/lib/python3.11/site-packages (from torch) (10.3.7.77)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\r\n",
      "  Obtaining dependency information for nvidia-cusolver-cu12==11.7.1.2 from https://files.pythonhosted.org/packages/f0/6e/c2cf12c9ff8b872e92b4a5740701e51ff17689c4d726fca91875b07f655d/nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\r\n",
      "  Obtaining dependency information for nvidia-cusparse-cu12==12.5.4.2 from https://files.pythonhosted.org/packages/06/1e/b8b7c2f4099a37b96af5c9bb158632ea9e5d9d27d7391d7eb8fc45236674/nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/jala6738/.local/lib/python3.11/site-packages (from torch) (0.6.3)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/jala6738/.local/lib/python3.11/site-packages (from torch) (2.26.2)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/jala6738/.local/lib/python3.11/site-packages (from torch) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/jala6738/.local/lib/python3.11/site-packages (from torch) (12.6.85)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/jala6738/.local/lib/python3.11/site-packages (from torch) (1.11.1.6)\r\n",
      "Requirement already satisfied: triton==3.3.0 in /home/jala6738/.local/lib/python3.11/site-packages (from torch) (3.3.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools>=40.8.0 in /curc/sw/anaconda3/2023.09/lib/python3.11/site-packages (from triton==3.3.0->torch) (68.0.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /curc/sw/anaconda3/2023.09/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /curc/sw/anaconda3/2023.09/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\r\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 28] No space left on device: '/home/jala6738/.local/lib/python3.11/site-packages/nvidia/__init__.py'\r\n",
      "\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCollatorWithPadding\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict, Dataset, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EvalPrediction\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1129f-a3ec-445b-a51b-711b0c6160e5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac751cef-b516-4a15-9074-e88bf860097b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_dict = load_dataset(\"csv\", data_files=\"data/gutenberg/uniform_excerpts_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c875ff-2ede-4d28-a2bf-c80044728ab6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/gutenberg/uniform_excerpts_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f65795b-0317-4acb-b0ce-fbb7c2f14830",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df[\"label_id\"] = label_encoder.fit_transform(df[\"label\"])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8793fdf9-98b5-4a79-afc8-b51a7e55f120",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df, val_test_df = train_test_split(df, test_size=0.15, stratify=df[\"label_id\"], random_state=104, shuffle=True)\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.5, stratify=val_test_df[\"label_id\"], random_state=104, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c483a2-c8d0-40a9-877a-e1efb56d317f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df[[\"text\", \"label_id\"]].rename(columns={\"label_id\": \"labels\"}))\n",
    "eval_dataset = Dataset.from_pandas(val_df[[\"text\", \"label_id\"]].rename(columns={\"label_id\": \"labels\"}))\n",
    "test_dataset = Dataset.from_pandas(test_df[[\"text\", \"label_id\"]].rename(columns={\"label_id\": \"labels\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0158cbd3-667c-4fa3-a1f5-4fba1cb6769b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model_path = \"google-bert/bert-base-uncased\"\n",
    "\n",
    "\n",
    "\n",
    "def tokenize_dataset(model_name, train_df, val_df, test_df):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"], truncation=True, padding=\"max_length\", max_length=256\n",
    "        )\n",
    "\n",
    "    def prepare(dataset):\n",
    "        dataset = Dataset.from_pandas(dataset[[\"text\", \"label_id\"]].rename(columns={\"label_id\": \"labels\"}))\n",
    "        dataset = dataset.map(tokenize_function, batched=True)\n",
    "        dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "        return dataset\n",
    "\n",
    "    return tokenizer, prepare(train_df), prepare(val_df), prepare(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d81046",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hyperparamaters\n",
    "lr = 1e-4\n",
    "batch_size = 16\n",
    "num_epochs = 4\n",
    "\n",
    "def train_model(model_path, label_encoder, train_dataset, eval_dataset, tokenizer):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"bert-english-classifier_teacher\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        learning_rate=lr,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=num_epochs,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\"\n",
    "    )\n",
    "\n",
    "\n",
    "    def compute_metrics(p: EvalPrediction):\n",
    "        preds = np.argmax(p.predictions, axis=1)\n",
    "        return {\"accuracy\": accuracy_score(p.label_ids, preds)}\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer),\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer.train()\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb75b01-870b-4e5c-8e65-c65625714589",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels = len(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09d93dd-10ba-4bd9-a74f-bff6a3253120",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''#freeze all base model parameters\n",
    "for name, param in model.base_model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#unfreeze base model pooling layers\n",
    "for name, param in model.base_model.named_parameters():\n",
    "    if \"pooler\" in name:\n",
    "        param.requires_grad = True'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf9603-4b08-4af0-b801-e41401adf561",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define text preprocessing\n",
    "'''def preprocess_function(examples):\n",
    "    #return tokenized text with truncation and padding\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=True)'''\n",
    "\n",
    "#preprocess all datasets\n",
    "'''train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "eval_dataset = eval_dataset.map(preprocess_function, batched=True)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c9d34-50c7-432a-bca2-84cbe4ea17ae",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer, train_dataset, val_dataset, test_dataset = tokenize_dataset(model_path, train_df, val_df, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931f1a18-cf03-423c-91a1-d42195a5d289",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff742a4-bf80-4ff4-8478-a1486c2e37f7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "'''#hyperparameters\n",
    "lr = 1e-4\n",
    "batch_size = 16\n",
    "num_epochs = 4\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"bert-english-classifier_teacher\",\n",
    "    learning_rate = lr,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size = batch_size,\n",
    "    num_train_epochs = num_epochs,\n",
    "    logging_strategy = \"epoch\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    load_best_model_at_end = True,\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8b494-2dfc-4ffc-b4cb-f1798b063c9e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''#TODO: When running train_dataset and eval_dataset, there is a tensor error where the trainer cant create a tensor. From what I gather, this might be\n",
    "# issue pertaining to the label in the uniform_excerpts dataset which isn't a flat integer.\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = eval_dataset,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()'''\n",
    "trainer = train_model(\n",
    "    model_path=model_path,\n",
    "    label_encoder=label_encoder,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec227d9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = trainer.evaluate(test_dataset)\n",
    "print(\"Test Results:\", results)\n",
    "predictions = trainer.predict(test_dataset)\n",
    "pred_labels = np.argmax(predictions.predictions, axis=1)\n",
    "true_labels = predictions.label_ids\n",
    "print(classification_report(true_labels, pred_labels, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aff816-2426-4f3b-929e-83456fb691e9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.650755,
   "end_time": "2025-04-25T03:51:23.626917",
   "environment_variables": {},
   "exception": true,
   "input_path": "Bert.ipynb",
   "output_path": "output_notebook.ipynb",
   "parameters": {},
   "start_time": "2025-04-25T03:51:02.976162",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
